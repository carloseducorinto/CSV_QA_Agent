# ğŸ¤– Guia de IntegraÃ§Ã£o LLM - QuestionUnderstandingAgent

## ğŸ“‹ VisÃ£o Geral

A classe `QuestionUnderstandingAgent` foi refatorada para incluir um mecanismo hÃ­brido de interpretaÃ§Ã£o de perguntas:

1. **ğŸ”¥ Primeira tentativa**: LLM (ChatOpenAI via LangChain)
2. **ğŸ”„ Fallback**: Sistema baseado em regex (mÃ©todo original)

---

## ğŸš€ ConfiguraÃ§Ã£o

### PrÃ©-requisitos

```bash
pip install langchain-openai
```

### ConfiguraÃ§Ã£o da API Key

```bash
# No Windows
set OPENAI_API_KEY=sua_api_key_aqui

# No Linux/Mac
export OPENAI_API_KEY=sua_api_key_aqui
```

### Ou no cÃ³digo Python:

```python
import os
os.environ['OPENAI_API_KEY'] = 'sua_api_key_aqui'
```

---

## ğŸ’¡ Como Funciona

### 1. InicializaÃ§Ã£o do Agente

```python
from agents.question_understanding import QuestionUnderstandingAgent

# O agente detecta automaticamente se LLM estÃ¡ disponÃ­vel
agent = QuestionUnderstandingAgent()

# Verificar status do LLM
if agent.llm:
    print("âœ… LLM disponÃ­vel")
else:
    print("âš¡ Usando apenas regex")
```

### 2. Processamento de Perguntas

```python
import pandas as pd

# Dados de exemplo
df = pd.DataFrame({
    'valor_total': [100, 200, 300],
    'produto': ['A', 'B', 'C']
})

dataframes = {'vendas.csv': df}

# Fazer pergunta
result = agent.understand_question(
    "Qual Ã© a soma dos valores totais?", 
    dataframes
)

print(f"MÃ©todo usado: {result['code_source']}")  # 'llm' ou 'regex'
print(f"CÃ³digo gerado: {result['generated_code']}")
```

---

## ğŸ”§ Funcionalidades Implementadas

### âœ… MÃ©todo `_generate_code_with_llm()`

**Assinatura:**
```python
def _generate_code_with_llm(self, question: str, df_name: str, df: pd.DataFrame) -> Optional[str]
```

**Funcionalidades:**
- ğŸ“Š Analisa colunas e tipos de dados
- ğŸ¯ Gera prompt contextualizado
- ğŸ” Valida cÃ³digo gerado
- ğŸ›¡ï¸ VerificaÃ§Ãµes bÃ¡sicas de seguranÃ§a

### âœ… MÃ©todo `_validate_llm_code()`

**ValidaÃ§Ãµes realizadas:**
- âœ… PresenÃ§a de `dataframes['arquivo']`
- âœ… PresenÃ§a de `result = ...`
- ğŸš« DetecÃ§Ã£o de cÃ³digo perigoso
- ğŸ” VerificaÃ§Ã£o de estrutura bÃ¡sica

### âœ… Sistema HÃ­brido

**Fluxo de processamento:**
1. ğŸ¤– **LLM**: Tenta gerar cÃ³digo usando ChatOpenAI
2. âœ… **ValidaÃ§Ã£o**: Verifica se cÃ³digo Ã© vÃ¡lido e seguro
3. ğŸ”„ **Fallback**: Se falhar, usa sistema regex
4. ğŸ“Š **Resultado**: Retorna cÃ³digo com metadados

---

## ğŸ“Š Estrutura de Resposta

```python
{
    'original_question': 'Qual Ã© a soma dos valores?',
    'target_dataframe': 'vendas.csv',
    'generated_code': 'df = dataframes["vendas.csv"]\nresult = df["valor_total"].sum()',
    'confidence': 0.95,
    'explanation': 'CÃ³digo gerado usando LLM (ChatOpenAI)',
    'code_source': 'llm',  # ou 'regex'
    'understood_intent': 'InterpretaÃ§Ã£o automÃ¡tica via LLM'
}
```

---

## ğŸ¯ Exemplos PrÃ¡ticos

### Exemplo 1: LLM DisponÃ­vel

```python
# Com API key configurada
agent = QuestionUnderstandingAgent()

result = agent.understand_question(
    "Mostre os 5 produtos com maior valor total",
    dataframes
)

# Resultado esperado:
# code_source: 'llm'
# confidence: 0.95
# generated_code: cÃ³digo sofisticado gerado pelo LLM
```

### Exemplo 2: Fallback para Regex

```python
# Sem API key ou LLM indisponÃ­vel
agent = QuestionUnderstandingAgent()

result = agent.understand_question(
    "Soma da coluna valor_total",
    dataframes
)

# Resultado esperado:
# code_source: 'regex'
# confidence: 1.0
# generated_code: cÃ³digo baseado em padrÃµes regex
```

### Exemplo 3: Tratamento de Erros

```python
result = agent.understand_question(
    "Pergunta muito complexa que falha em ambos os mÃ©todos",
    dataframes
)

if result.get('error'):
    print(f"Erro: {result['explanation']}")
    print(f"SugestÃµes: {result.get('fallback_suggestions', [])}")
```

---

## ğŸ“ˆ Vantagens da ImplementaÃ§Ã£o

### ğŸ¤– LLM (Primeira OpÃ§Ã£o)
- âœ… InterpretaÃ§Ã£o mais inteligente
- âœ… Suporte a perguntas complexas
- âœ… Flexibilidade para casos nÃ£o previstos
- âœ… GeraÃ§Ã£o de cÃ³digo mais sofisticado

### âš¡ Regex Fallback
- âœ… Sempre disponÃ­vel (nÃ£o depende de API)
- âœ… RÃ¡pido e confiÃ¡vel
- âœ… PadrÃµes otimizados e testados
- âœ… Zero custo operacional

### ğŸ”„ Sistema HÃ­brido
- âœ… MÃ¡xima disponibilidade
- âœ… Balanceamento custo/performance
- âœ… DegradaÃ§Ã£o graceful
- âœ… TransparÃªncia para o usuÃ¡rio

---

## ğŸ”’ SeguranÃ§a

### ValidaÃ§Ãµes Implementadas

```python
# Elementos obrigatÃ³rios
required_elements = [
    f"dataframes['{df_name}']",  # Carregamento do DataFrame
    "result =",                   # AtribuiÃ§Ã£o do resultado
]

# PadrÃµes perigosos bloqueados
dangerous_patterns = [
    'import os', 'import sys', 'exec(', 'eval(', 
    'open(', '__import__', 'subprocess'
]
```

---

## ğŸ“Š Monitoramento e Logs

### Logs DisponÃ­veis

```python
# Logs de inicializaÃ§Ã£o
logger.info("LLM initialized successfully with OpenAI")
logger.warning("OpenAI API key not found, LLM unavailable")

# Logs de processamento
logger.debug("LLM Prompt enviado: ...")
logger.debug("LLM Response recebida: ...")
logger.info("âœ… Usando cÃ³digo gerado por LLM")
logger.info("âš¡ Usando fallback: mÃ©todo baseado em regex")

# Logs de validaÃ§Ã£o
logger.info("âœ… CÃ³digo LLM validado com sucesso")
logger.warning("âŒ CÃ³digo LLM invÃ¡lido, serÃ¡ usado fallback")
```

### HistÃ³rico de Perguntas

```python
# Acessar histÃ³rico
history = agent.get_question_history()

for item in history:
    print(f"Pergunta: {item['original_question']}")
    print(f"MÃ©todo: {item['code_source']}")
    print(f"ConfianÃ§a: {item['confidence']}")
```

---

## ğŸ¯ Casos de Uso

### 1. Perguntas Simples (Regex)
- "Soma da coluna valor_total"
- "MÃ©dia de vendas"
- "MÃ¡ximo da receita"

### 2. Perguntas Complexas (LLM)
- "Mostre os 5 produtos mais vendidos por categoria"
- "Compare vendas do primeiro trimestre com o segundo"
- "Quais categorias tÃªm receita acima da mÃ©dia?"

### 3. Perguntas MultilÃ­ngues
- **PortuguÃªs**: "Qual Ã© a soma dos valores?"
- **InglÃªs**: "What is the total sales?"

---

## ğŸš€ PrÃ³ximos Passos

### PossÃ­veis Melhorias

1. **ğŸ”§ Cache de Respostas LLM**: Evitar chamadas repetidas
2. **ğŸ“Š MÃ©tricas de Performance**: Tempo de resposta LLM vs Regex
3. **ğŸ¯ Prompt Engineering**: Otimizar prompts para melhores resultados
4. **ğŸ”„ Modelos Alternativos**: Suporte a outros modelos alÃ©m do GPT-3.5

### ConfiguraÃ§Ãµes AvanÃ§adas

```python
# Personalizar modelo LLM
agent = QuestionUnderstandingAgent()
if agent.llm:
    agent.llm.model = "gpt-4"  # Usar GPT-4 para maior precisÃ£o
    agent.llm.temperature = 0.0  # Respostas mais determinÃ­sticas
```

---

## ğŸ‰ ConclusÃ£o

A refatoraÃ§Ã£o da `QuestionUnderstandingAgent` oferece:

- ğŸ¤– **InteligÃªncia Aumentada**: LLM para casos complexos
- âš¡ **Confiabilidade**: Fallback regex sempre disponÃ­vel
- ğŸ”’ **SeguranÃ§a**: ValidaÃ§Ã£o robusta de cÃ³digo gerado
- ğŸ“Š **TransparÃªncia**: Rastreabilidade completa do processo
- ğŸš€ **Flexibilidade**: AdaptÃ¡vel a diferentes cenÃ¡rios de uso

O sistema estÃ¡ pronto para produÃ§Ã£o e oferece uma experiÃªncia superior de interpretaÃ§Ã£o de perguntas em linguagem natural! 