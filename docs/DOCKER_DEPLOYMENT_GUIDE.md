# üê≥ Guia Completo de Deploy com Docker - CSV Q&A Agent

## üìã √çndice
1. [Vis√£o Geral](#-vis√£o-geral)
2. [Pr√©-requisitos](#-pr√©-requisitos)
3. [Setup B√°sico](#-setup-b√°sico)
4. [Configura√ß√£o Avan√ßada](#Ô∏è-configura√ß√£o-avan√ßada)
5. [Deploy em Produ√ß√£o](#-deploy-em-produ√ß√£o)
6. [Monitoramento](#-monitoramento)
7. [Troubleshooting](#-troubleshooting)
8. [Otimiza√ß√£o](#-otimiza√ß√£o)

---

## üéØ Vis√£o Geral

Este guia fornece instru√ß√µes completas para fazer o deploy do CSV Q&A Agent usando Docker, desde um setup local b√°sico at√© um ambiente de produ√ß√£o robusto.

### üèóÔ∏è Arquitetura Docker

```mermaid
graph TB
    A[üåê Load Balancer] --> B[üê≥ CSV-QA Container 1]
    A --> C[üê≥ CSV-QA Container 2] 
    A --> D[üê≥ CSV-QA Container N]
    
    B --> E[üìÅ Shared Volume /data]
    C --> E
    D --> E
    
    B --> F[üìä Logs Volume /logs]
    C --> F
    D --> F
    
    G[üîß Environment Variables] --> B
    G --> C
    G --> D
```

---

## üîß Pr√©-requisitos

### üíª Sistema Host
- **Docker Engine**: 20.10+ (recomendado 24.0+)
- **Docker Compose**: 2.0+ (inclu√≠do no Docker Desktop)
- **RAM**: M√≠nimo 4GB, recomendado 8GB+
- **Disco**: M√≠nimo 10GB livres
- **CPU**: 2+ cores recomendado

### üîë Credenciais (Opcional)
- **OpenAI API Key**: Para funcionalidades LLM avan√ßadas
- **Outras APIs**: Conforme necessidade futura

### üåê Rede
- **Porta 8501**: Dispon√≠vel para Streamlit
- **Internet**: Para download de depend√™ncias e APIs

---

## üöÄ Setup B√°sico

### 1Ô∏è‚É£ Clone e Prepara√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/CSV_QA_Agent.git
cd CSV_QA_Agent

# Verifique a estrutura
ls -la
```

### 2Ô∏è‚É£ Configura√ß√£o de Ambiente

```bash
# Copie o template de environment
cp .env.example .env

# Edite com suas configura√ß√µes
nano .env
```

**Conte√∫do do `.env`:**
```bash
# === CONFIGURA√á√ïES ESSENCIAIS ===
OPENAI_API_KEY=sk-sua-chave-aqui
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# === CONFIGURA√á√ïES STREAMLIT ===
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_SERVER_HEADLESS=true

# === CONFIGURA√á√ïES APLICA√á√ÉO ===
MAX_FILE_SIZE_MB=200
EXECUTION_TIMEOUT=30
ENABLE_LLM_INSIGHTS=true
DEFAULT_LANGUAGE=pt-BR

# === CONFIGURA√á√ïES AVAN√áADAS ===
CACHE_RESPONSES=true
VALIDATE_CODE_STRICT=true
SANDBOX_MODE=true
```

### 3Ô∏è‚É£ Build e Execu√ß√£o Simples

```bash
# Build da imagem
docker-compose build

# Execu√ß√£o em foreground (para debug)
docker-compose up

# Execu√ß√£o em background
docker-compose up -d
```

### 4Ô∏è‚É£ Verifica√ß√£o

```bash
# Verificar containers rodando
docker-compose ps

# Verificar logs
docker-compose logs -f

# Testar aplica√ß√£o
curl http://localhost:8501
```

---

## ‚öôÔ∏è Configura√ß√£o Avan√ßada

### üîß Docker Compose Customizado

**`docker-compose.override.yml`** (para desenvolvimento):
```yaml
services:
  csv-qa-agent:
    volumes:
      # Mount c√≥digo para desenvolvimento
      - .:/app
      # Persist data local
      - ./dev-data:/app/data
      - ./dev-logs:/app/logs
    environment:
      - LOG_LEVEL=DEBUG
      - STREAMLIT_SERVER_RUNONSAVE=true
    ports:
      - "8501:8501"
      - "8502:8502"  # Porta extra para debug
```

**`docker-compose.prod.yml`** (para produ√ß√£o):
```yaml
services:
  csv-qa-agent:
    build:
      context: .
      dockerfile: Dockerfile.prod
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    volumes:
      - app-data:/app/data
      - app-logs:/app/logs
    environment:
      - STREAMLIT_SERVER_ENABLECORS=false
      - STREAMLIT_SERVER_ENABLEXSRFPROTECTION=true

volumes:
  app-data:
    driver: local
  app-logs:
    driver: local
```

### üõ°Ô∏è Dockerfile Otimizado para Produ√ß√£o

**`Dockerfile.prod`:**
```dockerfile
# Build stage
FROM python:3.11-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt

# Production stage
FROM python:3.11-slim

WORKDIR /app

# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Install only runtime dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy wheels and install
COPY --from=builder /app/wheels /wheels
COPY requirements.txt .
RUN pip install --no-cache /wheels/*

# Copy application code
COPY --chown=appuser:appuser . .

# Create necessary directories
RUN mkdir -p /app/data /app/logs && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8501/_stcore/health || exit 1

# Expose port
EXPOSE 8501

# Start application
CMD ["streamlit", "run", "app.py", \
     "--server.port=8501", \
     "--server.address=0.0.0.0", \
     "--server.headless=true", \
     "--server.enableCORS=false"]
```

### üîó Networking Avan√ßado

**`docker-compose.network.yml`:**
```yaml
networks:
  csvqa-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

services:
  csv-qa-agent:
    networks:
      csvqa-network:
        ipv4_address: 172.20.0.10
  
  # Redis para cache (futuro)
  redis:
    image: redis:7-alpine
    networks:
      csvqa-network:
        ipv4_address: 172.20.0.20
    volumes:
      - redis-data:/data
  
  # Nginx para load balancing
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    networks:
      csvqa-network:
        ipv4_address: 172.20.0.5
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl

volumes:
  redis-data:
```

---

## üè¢ Deploy em Produ√ß√£o

### üéØ Cen√°rios de Deploy

#### üì¶ **Cen√°rio 1: VPS Simples**
```bash
# Deploy em um VPS Ubuntu/CentOS
cd /opt/csvqa
git pull origin main

# Build e deploy
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# Setup backup autom√°tico
crontab -e
# 0 2 * * * docker-compose exec csv-qa-agent python backup_data.py
```

#### ‚òÅÔ∏è **Cen√°rio 2: AWS ECS**
```yaml
# task-definition.json
{
  "family": "csvqa-task",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "csvqa-container",
      "image": "seu-registry/csvqa:latest",
      "portMappings": [
        {
          "containerPort": 8501,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "OPENAI_API_KEY",
          "valueFrom": "arn:aws:ssm:region:account:parameter/csvqa/openai-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/csvqa",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

#### üö¢ **Cen√°rio 3: Kubernetes**
```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: csvqa-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: csvqa
  template:
    metadata:
      labels:
        app: csvqa
    spec:
      containers:
      - name: csvqa
        image: csvqa:latest
        ports:
        - containerPort: 8501
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: csvqa-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 5
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: csvqa-service
spec:
  selector:
    app: csvqa
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8501
  type: LoadBalancer
```

### üîí Configura√ß√£o SSL/TLS

**`nginx.conf`:**
```nginx
upstream csvqa_backend {
    server csv-qa-agent:8501;
}

server {
    listen 80;
    server_name seu-dominio.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name seu-dominio.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    
    location / {
        proxy_pass http://csvqa_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req zone=api burst=20 nodelay;
}
```

---

## üìä Monitoramento

### üìà M√©tricas com Docker Stats

```bash
# Script de monitoramento
#!/bin/bash
# monitor.sh

echo "=== CSV Q&A Agent - Monitoring ==="
echo "Timestamp: $(date)"
echo ""

# Container status
echo "üì¶ Container Status:"
docker-compose ps

echo ""
echo "üìä Resource Usage:"
docker stats csv-qa-agent --no-stream

echo ""
echo "üìã Recent Logs (last 10 lines):"
docker-compose logs --tail=10 csv-qa-agent

echo ""
echo "üåê Health Check:"
curl -s -o /dev/null -w "HTTP Status: %{http_code}\nResponse Time: %{time_total}s\n" \
    http://localhost:8501/_stcore/health
```

### üìä M√©tricas Avan√ßadas com Prometheus

**`docker-compose.monitoring.yml`:**
```yaml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro

volumes:
  prometheus-data:
  grafana-data:
```

### üìä Dashboard Grafana Customizado

```json
{
  "dashboard": {
    "title": "CSV Q&A Agent Monitoring",
    "panels": [
      {
        "title": "Container CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{name=\"csv-qa-agent\"}[5m]) * 100"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph", 
        "targets": [
          {
            "expr": "container_memory_usage_bytes{name=\"csv-qa-agent\"} / 1024 / 1024 / 1024"
          }
        ]
      },
      {
        "title": "Request Count",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(increase(http_requests_total[5m]))"
          }
        ]
      }
    ]
  }
}
```

---

## üö® Troubleshooting

### üîç Diagn√≥stico Comum

#### **1. Container n√£o inicia**
```bash
# Verificar logs de build
docker-compose build --no-cache

# Verificar logs de startup
docker-compose logs csv-qa-agent

# Verificar configura√ß√µes
docker-compose config

# Verificar recursos do sistema
docker system df
docker system prune  # Limpar espa√ßo se necess√°rio
```

#### **2. Aplica√ß√£o inacess√≠vel**
```bash
# Verificar se o container est√° rodando
docker-compose ps

# Verificar porta binding
netstat -tlnp | grep 8501

# Verificar health da aplica√ß√£o
docker-compose exec csv-qa-agent curl http://localhost:8501/_stcore/health

# Verificar logs de rede
docker network ls
docker network inspect csv_qa_agent_default
```

#### **3. Performance lenta**
```bash
# Verificar recursos
docker stats csv-qa-agent

# Verificar logs de performance
docker-compose logs csv-qa-agent | grep "execution_time"

# Verificar configura√ß√£o de mem√≥ria
docker-compose config | grep memory

# Ajustar limites se necess√°rio
# No docker-compose.yml:
deploy:
  resources:
    limits:
      memory: 4G
    reservations:
      memory: 2G
```

#### **4. Erros de API OpenAI**
```bash
# Verificar vari√°vel de ambiente
docker-compose exec csv-qa-agent printenv | grep OPENAI

# Testar API key
docker-compose exec csv-qa-agent python -c "
import openai
client = openai.OpenAI()
print(client.models.list())
"

# Verificar logs de LLM
docker-compose logs csv-qa-agent | grep -i openai
```

### üõ†Ô∏è Comandos de Debug √öteis

```bash
# === CONTAINER DEBUGGING ===
# Acessar shell do container
docker-compose exec csv-qa-agent bash

# Verificar processos internos
docker-compose exec csv-qa-agent ps aux

# Verificar arquivos de configura√ß√£o
docker-compose exec csv-qa-agent cat config.py

# === LOGS AVAN√áADOS ===
# Logs com timestamp
docker-compose logs -t csv-qa-agent

# Logs de uma janela de tempo
docker-compose logs --since="2024-01-01T12:00:00" csv-qa-agent

# Logs em tempo real com filtro
docker-compose logs -f csv-qa-agent | grep ERROR

# === NETWORKING ===
# Verificar conectividade entre containers
docker-compose exec csv-qa-agent ping redis

# Verificar DNS interno
docker-compose exec csv-qa-agent nslookup csv-qa-agent

# === PERFORMANCE ===
# Profiling de mem√≥ria
docker-compose exec csv-qa-agent python -m memory_profiler app.py

# Verificar uso de disco
docker-compose exec csv-qa-agent df -h
```

### üìã Checklist de Troubleshooting

- [ ] **Verificar logs de build** - Erros durante constru√ß√£o da imagem
- [ ] **Verificar vari√°veis de ambiente** - Configura√ß√µes corretas
- [ ] **Verificar portas** - N√£o h√° conflitos de porta
- [ ] **Verificar recursos** - RAM e CPU suficientes
- [ ] **Verificar rede** - Conectividade entre containers
- [ ] **Verificar volumes** - Montagem correta de dados
- [ ] **Verificar permiss√µes** - Usu√°rio tem acesso aos arquivos
- [ ] **Verificar health checks** - Aplica√ß√£o responde corretamente

---

## ‚ö° Otimiza√ß√£o

### üöÄ Performance Docker

#### **1. Build Optimization**
```dockerfile
# Use multi-stage builds
FROM python:3.11-slim as base
FROM base as deps
FROM base as production

# Use .dockerignore efetivo
echo "
**/.git
**/node_modules
**/venv
**/__pycache__
**/logs
**/data
" > .dockerignore

# Cache layers de depend√™ncias
COPY requirements.txt .
RUN pip install -r requirements.txt
# S√≥ depois copiar c√≥digo (que muda mais)
COPY . .
```

#### **2. Runtime Optimization**
```yaml
# docker-compose.yml otimizado
services:
  csv-qa-agent:
    # Limitar recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    
    # Configurar restart policy
    restart: unless-stopped
    
    # Usar init para reaping de processos
    init: true
    
    # Configurar logging otimizado
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
```

#### **3. Caching Strategy**
```bash
# Build com BuildKit para cache avan√ßado
DOCKER_BUILDKIT=1 docker-compose build

# Cache de layers entre builds
docker-compose build --build-arg BUILDKIT_INLINE_CACHE=1

# Registry cache (para CI/CD)
docker buildx build --cache-from=type=registry,ref=registry/cache \
  --cache-to=type=registry,ref=registry/cache,mode=max
```

### üíæ Storage Optimization

#### **1. Volume Management**
```yaml
# Volumes nomeados para performance
volumes:
  app-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/csvqa/data
  
  app-cache:
    driver: local
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: size=1G
```

#### **2. Log Rotation**
```bash
# Configurar logrotate
sudo tee /etc/logrotate.d/docker-csvqa <<EOF
/var/lib/docker/containers/*/*-json.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
    postrotate
        docker kill --signal=USR1 \$(docker ps -q) || true
    endscript
}
EOF
```

### üåê Network Optimization

```yaml
# Configura√ß√£o de rede otimizada
networks:
  csvqa-net:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: csvqa-br
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
```

---

## üìà Scaling e Alta Disponibilidade

### üîÑ Horizontal Scaling

```yaml
# docker-compose.scale.yml
services:
  csv-qa-agent:
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx-lb.conf:/etc/nginx/nginx.conf
    depends_on:
      - csv-qa-agent

  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
```

**`nginx-lb.conf`:**
```nginx
upstream csvqa_cluster {
    least_conn;
    server csv-qa-agent_1:8501 weight=1 max_fails=3 fail_timeout=30s;
    server csv-qa-agent_2:8501 weight=1 max_fails=3 fail_timeout=30s;
    server csv-qa-agent_3:8501 weight=1 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    
    location / {
        proxy_pass http://csvqa_cluster;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Health check
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    location /health {
        access_log off;
        add_header Content-Type text/plain;
        return 200 "healthy\n";
    }
}
```

### üîß Deploy com Docker Swarm

```bash
# Inicializar swarm
docker swarm init

# Deploy stack
docker stack deploy -c docker-compose.swarm.yml csvqa

# Verificar servi√ßos
docker service ls
docker service ps csvqa_csv-qa-agent

# Scaling manual
docker service scale csvqa_csv-qa-agent=5

# Verificar logs do cluster
docker service logs csvqa_csv-qa-agent
```

---

## üîê Seguran√ßa em Produ√ß√£o

### üõ°Ô∏è Hardening do Container

```dockerfile
# Security-focused Dockerfile
FROM python:3.11-slim

# Criar usu√°rio n√£o-root
RUN groupadd -r csvqa && useradd -r -g csvqa csvqa

# Instalar apenas depend√™ncias necess√°rias
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Definir working directory
WORKDIR /app

# Copiar e instalar depend√™ncias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY --chown=csvqa:csvqa . .

# Configurar permiss√µes
RUN chmod -R 755 /app && \
    chmod -R 644 /app/*.py && \
    mkdir -p /app/data /app/logs && \
    chown -R csvqa:csvqa /app

# Mudar para usu√°rio n√£o-root
USER csvqa

# Definir vari√°veis de seguran√ßa
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8501/_stcore/health || exit 1

# Expor porta
EXPOSE 8501

# Comando de inicializa√ß√£o
CMD ["streamlit", "run", "app.py", \
     "--server.port=8501", \
     "--server.address=0.0.0.0", \
     "--server.headless=true"]
```

### üîí Secrets Management

```yaml
# docker-compose.secrets.yml
services:
  csv-qa-agent:
    secrets:
      - openai_api_key
      - app_secret_key
    environment:
      - OPENAI_API_KEY_FILE=/run/secrets/openai_api_key
      - APP_SECRET_KEY_FILE=/run/secrets/app_secret_key

secrets:
  openai_api_key:
    file: ./secrets/openai_api_key.txt
  app_secret_key:
    file: ./secrets/app_secret_key.txt
```

---

## üìö Conclus√£o

Este guia cobriu todos os aspectos essenciais para deploy do CSV Q&A Agent com Docker:

‚úÖ **Setup b√°sico** para desenvolvimento  
‚úÖ **Configura√ß√£o avan√ßada** para customiza√ß√£o  
‚úÖ **Deploy em produ√ß√£o** com diferentes cen√°rios  
‚úÖ **Monitoramento** e m√©tricas  
‚úÖ **Troubleshooting** detalhado  
‚úÖ **Otimiza√ß√£o** de performance  
‚úÖ **Scaling** e alta disponibilidade  
‚úÖ **Seguran√ßa** em produ√ß√£o  

### üéØ Pr√≥ximos Passos Recomendados

1. **Implementar monitoramento** com Prometheus/Grafana
2. **Configurar backup autom√°tico** de dados e configura√ß√µes
3. **Setup de CI/CD** para deploys automatizados
4. **Implementar service mesh** para microservi√ßos (futuro)
5. **Configurar disaster recovery** para ambientes cr√≠ticos

### üìû Suporte

Para d√∫vidas espec√≠ficas sobre Docker:
- üìß **Email**: docker-support@csvqaagent.com
- üêõ **Issues**: [GitHub Issues](https://github.com/seu-usuario/CSV_QA_Agent/issues)
- üí¨ **Discord**: [Canal #docker-help](https://discord.gg/csvqa)

---

*Documenta√ß√£o criada com ‚ù§Ô∏è para simplificar o deploy do CSV Q&A Agent* 